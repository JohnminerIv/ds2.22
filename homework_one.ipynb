{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the load_boston() function from sklearn.datasets\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.columns = boston.feature_names\n",
    "bos['PRICE'] = boston.target\n",
    "\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE from test data compared to prediction\n",
      "29.782245092302336\n",
      "R^2 from test data compared to prediction\n",
      "0.6354638433202133\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bos[boston.feature_names], bos['PRICE'], test_size=0.25, random_state=0)\n",
    "\n",
    "basic_reg = LinearRegression()\n",
    "basic_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = basic_reg.predict(X_test)\n",
    "print('MSE from test data compared to prediction')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print('R^2 from test data compared to prediction')\n",
    "print(r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnminer/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "379/379 [==============================] - 0s 742us/step - loss: 7173.6511 - mse: 7173.6538\n",
      "Epoch 2/200\n",
      "379/379 [==============================] - 0s 550us/step - loss: 334.7064 - mse: 334.7064\n",
      "Epoch 3/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 284.1626 - mse: 284.1627\n",
      "Epoch 4/200\n",
      "379/379 [==============================] - 0s 628us/step - loss: 247.4893 - mse: 247.4894\n",
      "Epoch 5/200\n",
      "379/379 [==============================] - 0s 620us/step - loss: 223.0686 - mse: 223.0687\n",
      "Epoch 6/200\n",
      "379/379 [==============================] - 0s 652us/step - loss: 195.5531 - mse: 195.5531\n",
      "Epoch 7/200\n",
      "379/379 [==============================] - 0s 557us/step - loss: 171.6611 - mse: 171.6611\n",
      "Epoch 8/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 150.2776 - mse: 150.2776\n",
      "Epoch 9/200\n",
      "379/379 [==============================] - 0s 595us/step - loss: 131.8475 - mse: 131.8475\n",
      "Epoch 10/200\n",
      "379/379 [==============================] - 0s 628us/step - loss: 114.4208 - mse: 114.4208\n",
      "Epoch 11/200\n",
      "379/379 [==============================] - 0s 576us/step - loss: 100.6344 - mse: 100.6344\n",
      "Epoch 12/200\n",
      "379/379 [==============================] - 0s 557us/step - loss: 89.1566 - mse: 89.1566\n",
      "Epoch 13/200\n",
      "379/379 [==============================] - 0s 531us/step - loss: 79.0956 - mse: 79.0956\n",
      "Epoch 14/200\n",
      "379/379 [==============================] - 0s 554us/step - loss: 71.4955 - mse: 71.4956\n",
      "Epoch 15/200\n",
      "379/379 [==============================] - 0s 570us/step - loss: 67.4446 - mse: 67.4447\n",
      "Epoch 16/200\n",
      "379/379 [==============================] - 0s 537us/step - loss: 62.6820 - mse: 62.6820\n",
      "Epoch 17/200\n",
      "379/379 [==============================] - 0s 545us/step - loss: 58.4981 - mse: 58.4981\n",
      "Epoch 18/200\n",
      "379/379 [==============================] - 0s 500us/step - loss: 58.1621 - mse: 58.1621\n",
      "Epoch 19/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 56.2711 - mse: 56.2711\n",
      "Epoch 20/200\n",
      "379/379 [==============================] - 0s 568us/step - loss: 54.9196 - mse: 54.9195\n",
      "Epoch 21/200\n",
      "379/379 [==============================] - 0s 624us/step - loss: 53.8975 - mse: 53.8975\n",
      "Epoch 22/200\n",
      "379/379 [==============================] - 0s 653us/step - loss: 52.2183 - mse: 52.2183\n",
      "Epoch 23/200\n",
      "379/379 [==============================] - 0s 629us/step - loss: 50.7010 - mse: 50.7010\n",
      "Epoch 24/200\n",
      "379/379 [==============================] - 0s 636us/step - loss: 50.2465 - mse: 50.2465\n",
      "Epoch 25/200\n",
      "379/379 [==============================] - 0s 552us/step - loss: 48.8663 - mse: 48.8663\n",
      "Epoch 26/200\n",
      "379/379 [==============================] - 0s 560us/step - loss: 48.0987 - mse: 48.0987\n",
      "Epoch 27/200\n",
      "379/379 [==============================] - 0s 586us/step - loss: 49.7078 - mse: 49.7079\n",
      "Epoch 28/200\n",
      "379/379 [==============================] - 0s 546us/step - loss: 48.0750 - mse: 48.0750\n",
      "Epoch 29/200\n",
      "379/379 [==============================] - 0s 532us/step - loss: 48.3749 - mse: 48.3749\n",
      "Epoch 30/200\n",
      "379/379 [==============================] - 0s 531us/step - loss: 46.4557 - mse: 46.4557\n",
      "Epoch 31/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 46.9840 - mse: 46.9839\n",
      "Epoch 32/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 45.8562 - mse: 45.8562\n",
      "Epoch 33/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 45.7546 - mse: 45.7546\n",
      "Epoch 34/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 45.5635 - mse: 45.5635\n",
      "Epoch 35/200\n",
      "379/379 [==============================] - 0s 523us/step - loss: 45.1189 - mse: 45.1189\n",
      "Epoch 36/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 42.8129 - mse: 42.8129\n",
      "Epoch 37/200\n",
      "379/379 [==============================] - 0s 496us/step - loss: 43.0241 - mse: 43.0241\n",
      "Epoch 38/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 43.1530 - mse: 43.1530\n",
      "Epoch 39/200\n",
      "379/379 [==============================] - 0s 553us/step - loss: 44.1413 - mse: 44.1413\n",
      "Epoch 40/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 41.8444 - mse: 41.8444\n",
      "Epoch 41/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 42.2964 - mse: 42.2964\n",
      "Epoch 42/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 42.6750 - mse: 42.6750\n",
      "Epoch 43/200\n",
      "379/379 [==============================] - 0s 540us/step - loss: 40.6924 - mse: 40.6923\n",
      "Epoch 44/200\n",
      "379/379 [==============================] - 0s 560us/step - loss: 41.7212 - mse: 41.7212\n",
      "Epoch 45/200\n",
      "379/379 [==============================] - 0s 542us/step - loss: 41.5871 - mse: 41.5871\n",
      "Epoch 46/200\n",
      "379/379 [==============================] - 0s 601us/step - loss: 41.1127 - mse: 41.1127\n",
      "Epoch 47/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 40.5648 - mse: 40.5648\n",
      "Epoch 48/200\n",
      "379/379 [==============================] - 0s 554us/step - loss: 39.4312 - mse: 39.4312\n",
      "Epoch 49/200\n",
      "379/379 [==============================] - 0s 639us/step - loss: 40.5748 - mse: 40.5748\n",
      "Epoch 50/200\n",
      "379/379 [==============================] - 0s 619us/step - loss: 41.3636 - mse: 41.3636\n",
      "Epoch 51/200\n",
      "379/379 [==============================] - 0s 624us/step - loss: 41.8803 - mse: 41.8803\n",
      "Epoch 52/200\n",
      "379/379 [==============================] - 0s 644us/step - loss: 39.9221 - mse: 39.9221\n",
      "Epoch 53/200\n",
      "379/379 [==============================] - 0s 627us/step - loss: 39.4041 - mse: 39.4041\n",
      "Epoch 54/200\n",
      "379/379 [==============================] - 0s 629us/step - loss: 38.2551 - mse: 38.2551\n",
      "Epoch 55/200\n",
      "379/379 [==============================] - 0s 545us/step - loss: 39.2385 - mse: 39.2385\n",
      "Epoch 56/200\n",
      "379/379 [==============================] - 0s 580us/step - loss: 38.7339 - mse: 38.7339\n",
      "Epoch 57/200\n",
      "379/379 [==============================] - 0s 558us/step - loss: 38.8072 - mse: 38.8072\n",
      "Epoch 58/200\n",
      "379/379 [==============================] - 0s 642us/step - loss: 38.4522 - mse: 38.4522\n",
      "Epoch 59/200\n",
      "379/379 [==============================] - 0s 635us/step - loss: 38.4137 - mse: 38.4137\n",
      "Epoch 60/200\n",
      "379/379 [==============================] - 0s 580us/step - loss: 38.8925 - mse: 38.8925\n",
      "Epoch 61/200\n",
      "379/379 [==============================] - 0s 570us/step - loss: 37.4829 - mse: 37.4829\n",
      "Epoch 62/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 36.8057 - mse: 36.8057\n",
      "Epoch 63/200\n",
      "379/379 [==============================] - 0s 517us/step - loss: 38.1553 - mse: 38.1553\n",
      "Epoch 64/200\n",
      "379/379 [==============================] - 0s 515us/step - loss: 37.8526 - mse: 37.8526\n",
      "Epoch 65/200\n",
      "379/379 [==============================] - 0s 568us/step - loss: 37.1506 - mse: 37.1507\n",
      "Epoch 66/200\n",
      "379/379 [==============================] - 0s 530us/step - loss: 35.3737 - mse: 35.3737\n",
      "Epoch 67/200\n",
      "379/379 [==============================] - 0s 608us/step - loss: 35.7567 - mse: 35.7567\n",
      "Epoch 68/200\n",
      "379/379 [==============================] - 0s 583us/step - loss: 35.3147 - mse: 35.3146\n",
      "Epoch 69/200\n",
      "379/379 [==============================] - 0s 561us/step - loss: 36.4885 - mse: 36.4885\n",
      "Epoch 70/200\n",
      "379/379 [==============================] - 0s 523us/step - loss: 35.6886 - mse: 35.6886\n",
      "Epoch 71/200\n",
      "379/379 [==============================] - 0s 523us/step - loss: 34.6442 - mse: 34.6442\n",
      "Epoch 72/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 36.6712 - mse: 36.6712\n",
      "Epoch 73/200\n",
      "379/379 [==============================] - 0s 521us/step - loss: 35.9234 - mse: 35.9234\n",
      "Epoch 74/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 36.0248 - mse: 36.0248\n",
      "Epoch 75/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 35.2622 - mse: 35.2622\n",
      "Epoch 76/200\n",
      "379/379 [==============================] - 0s 500us/step - loss: 34.3721 - mse: 34.3721\n",
      "Epoch 77/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 34.0471 - mse: 34.0471\n",
      "Epoch 78/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 34.2104 - mse: 34.2104\n",
      "Epoch 79/200\n",
      "379/379 [==============================] - 0s 595us/step - loss: 34.3948 - mse: 34.3948\n",
      "Epoch 80/200\n",
      "379/379 [==============================] - 0s 521us/step - loss: 35.4827 - mse: 35.4827\n",
      "Epoch 81/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 34.3772 - mse: 34.3772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "379/379 [==============================] - 0s 526us/step - loss: 34.2991 - mse: 34.2991\n",
      "Epoch 83/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 34.7317 - mse: 34.7317\n",
      "Epoch 84/200\n",
      "379/379 [==============================] - 0s 495us/step - loss: 33.5389 - mse: 33.5389\n",
      "Epoch 85/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 34.5359 - mse: 34.5359\n",
      "Epoch 86/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 34.2432 - mse: 34.2433\n",
      "Epoch 87/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 33.3008 - mse: 33.3008\n",
      "Epoch 88/200\n",
      "379/379 [==============================] - 0s 533us/step - loss: 33.5110 - mse: 33.5110\n",
      "Epoch 89/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 34.0610 - mse: 34.0610\n",
      "Epoch 90/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 33.7757 - mse: 33.7757\n",
      "Epoch 91/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 33.0482 - mse: 33.0482\n",
      "Epoch 92/200\n",
      "379/379 [==============================] - 0s 621us/step - loss: 32.6341 - mse: 32.6341\n",
      "Epoch 93/200\n",
      "379/379 [==============================] - 0s 539us/step - loss: 32.5988 - mse: 32.5988\n",
      "Epoch 94/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 32.6025 - mse: 32.6025\n",
      "Epoch 95/200\n",
      "379/379 [==============================] - 0s 556us/step - loss: 32.6090 - mse: 32.6090\n",
      "Epoch 96/200\n",
      "379/379 [==============================] - 0s 621us/step - loss: 32.6081 - mse: 32.6081\n",
      "Epoch 97/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 31.9623 - mse: 31.9623\n",
      "Epoch 98/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 32.6080 - mse: 32.6080\n",
      "Epoch 99/200\n",
      "379/379 [==============================] - 0s 538us/step - loss: 32.5307 - mse: 32.5307\n",
      "Epoch 100/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 31.6352 - mse: 31.6352\n",
      "Epoch 101/200\n",
      "379/379 [==============================] - 0s 536us/step - loss: 32.0671 - mse: 32.0672\n",
      "Epoch 102/200\n",
      "379/379 [==============================] - 0s 492us/step - loss: 31.9517 - mse: 31.9517\n",
      "Epoch 103/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 31.5354 - mse: 31.5354\n",
      "Epoch 104/200\n",
      "379/379 [==============================] - 0s 497us/step - loss: 31.7640 - mse: 31.7640\n",
      "Epoch 105/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 30.9822 - mse: 30.9823\n",
      "Epoch 106/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 30.2375 - mse: 30.2375\n",
      "Epoch 107/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 30.7003 - mse: 30.7003\n",
      "Epoch 108/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 31.5587 - mse: 31.5587\n",
      "Epoch 109/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 32.3287 - mse: 32.3287\n",
      "Epoch 110/200\n",
      "379/379 [==============================] - 0s 495us/step - loss: 30.8638 - mse: 30.8638\n",
      "Epoch 111/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 31.4526 - mse: 31.4526\n",
      "Epoch 112/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 31.2406 - mse: 31.2406\n",
      "Epoch 113/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 30.9740 - mse: 30.9740\n",
      "Epoch 114/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 29.9624 - mse: 29.9624\n",
      "Epoch 115/200\n",
      "379/379 [==============================] - 0s 522us/step - loss: 30.1573 - mse: 30.1573\n",
      "Epoch 116/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 30.8547 - mse: 30.8547\n",
      "Epoch 117/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 31.0214 - mse: 31.0214\n",
      "Epoch 118/200\n",
      "379/379 [==============================] - 0s 497us/step - loss: 29.5735 - mse: 29.5735\n",
      "Epoch 119/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 30.0362 - mse: 30.0361\n",
      "Epoch 120/200\n",
      "379/379 [==============================] - 0s 500us/step - loss: 29.0480 - mse: 29.0480\n",
      "Epoch 121/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 29.6042 - mse: 29.6042\n",
      "Epoch 122/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 30.1496 - mse: 30.1496\n",
      "Epoch 123/200\n",
      "379/379 [==============================] - 0s 532us/step - loss: 28.8316 - mse: 28.8316\n",
      "Epoch 124/200\n",
      "379/379 [==============================] - 0s 564us/step - loss: 30.1860 - mse: 30.1860\n",
      "Epoch 125/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 29.8090 - mse: 29.8090\n",
      "Epoch 126/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 29.3175 - mse: 29.3175\n",
      "Epoch 127/200\n",
      "379/379 [==============================] - 0s 515us/step - loss: 31.0663 - mse: 31.0663\n",
      "Epoch 128/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 29.7382 - mse: 29.7382\n",
      "Epoch 129/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 29.9603 - mse: 29.9603\n",
      "Epoch 130/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 29.0401 - mse: 29.0401\n",
      "Epoch 131/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 29.5771 - mse: 29.5771\n",
      "Epoch 132/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 29.8796 - mse: 29.8796\n",
      "Epoch 133/200\n",
      "379/379 [==============================] - 0s 547us/step - loss: 30.2176 - mse: 30.2176\n",
      "Epoch 134/200\n",
      "379/379 [==============================] - 0s 564us/step - loss: 30.5713 - mse: 30.5713\n",
      "Epoch 135/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 29.9490 - mse: 29.9490\n",
      "Epoch 136/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 29.2387 - mse: 29.2387\n",
      "Epoch 137/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 29.0521 - mse: 29.0521\n",
      "Epoch 138/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 28.8911 - mse: 28.8911\n",
      "Epoch 139/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 28.7935 - mse: 28.7935\n",
      "Epoch 140/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 27.6673 - mse: 27.6673\n",
      "Epoch 141/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 29.8689 - mse: 29.8689\n",
      "Epoch 142/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 28.4373 - mse: 28.4373\n",
      "Epoch 143/200\n",
      "379/379 [==============================] - 0s 526us/step - loss: 28.5342 - mse: 28.5341\n",
      "Epoch 144/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 29.5823 - mse: 29.5823\n",
      "Epoch 145/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 28.8448 - mse: 28.8448\n",
      "Epoch 146/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 28.2204 - mse: 28.2204\n",
      "Epoch 147/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 27.9045 - mse: 27.9045\n",
      "Epoch 148/200\n",
      "379/379 [==============================] - 0s 545us/step - loss: 28.0824 - mse: 28.0824\n",
      "Epoch 149/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 30.1872 - mse: 30.1872\n",
      "Epoch 150/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 28.9141 - mse: 28.9141\n",
      "Epoch 151/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 27.9155 - mse: 27.9155\n",
      "Epoch 152/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 27.7166 - mse: 27.7166\n",
      "Epoch 153/200\n",
      "379/379 [==============================] - 0s 538us/step - loss: 26.7755 - mse: 26.7755\n",
      "Epoch 154/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 28.0126 - mse: 28.0126\n",
      "Epoch 155/200\n",
      "379/379 [==============================] - 0s 515us/step - loss: 27.3590 - mse: 27.3590\n",
      "Epoch 156/200\n",
      "379/379 [==============================] - 0s 500us/step - loss: 27.6221 - mse: 27.6221\n",
      "Epoch 157/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 27.3383 - mse: 27.3383\n",
      "Epoch 158/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 27.0928 - mse: 27.0928\n",
      "Epoch 159/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 28.2346 - mse: 28.2346\n",
      "Epoch 160/200\n",
      "379/379 [==============================] - 0s 549us/step - loss: 26.5105 - mse: 26.5105\n",
      "Epoch 161/200\n",
      "379/379 [==============================] - 0s 521us/step - loss: 26.2602 - mse: 26.2602\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 508us/step - loss: 26.4963 - mse: 26.4963\n",
      "Epoch 163/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 26.6820 - mse: 26.6820\n",
      "Epoch 164/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 28.3599 - mse: 28.3599\n",
      "Epoch 165/200\n",
      "379/379 [==============================] - 0s 573us/step - loss: 27.2351 - mse: 27.2351\n",
      "Epoch 166/200\n",
      "379/379 [==============================] - 0s 521us/step - loss: 28.1809 - mse: 28.1809\n",
      "Epoch 167/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 27.7335 - mse: 27.7334\n",
      "Epoch 168/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 28.4392 - mse: 28.4392\n",
      "Epoch 169/200\n",
      "379/379 [==============================] - 0s 495us/step - loss: 26.7107 - mse: 26.7107\n",
      "Epoch 170/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 27.1508 - mse: 27.1508\n",
      "Epoch 171/200\n",
      "379/379 [==============================] - 0s 495us/step - loss: 27.8750 - mse: 27.8750\n",
      "Epoch 172/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 28.5265 - mse: 28.5265\n",
      "Epoch 173/200\n",
      "379/379 [==============================] - 0s 522us/step - loss: 26.5653 - mse: 26.5653\n",
      "Epoch 174/200\n",
      "379/379 [==============================] - 0s 526us/step - loss: 27.1554 - mse: 27.1554\n",
      "Epoch 175/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 28.0075 - mse: 28.0075\n",
      "Epoch 176/200\n",
      "379/379 [==============================] - 0s 497us/step - loss: 26.4623 - mse: 26.4623\n",
      "Epoch 177/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 27.3914 - mse: 27.3914\n",
      "Epoch 178/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 28.7723 - mse: 28.7723\n",
      "Epoch 179/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 26.2866 - mse: 26.2866\n",
      "Epoch 180/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 27.1618 - mse: 27.1618\n",
      "Epoch 181/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 27.0053 - mse: 27.0053\n",
      "Epoch 182/200\n",
      "379/379 [==============================] - 0s 546us/step - loss: 26.3529 - mse: 26.3529\n",
      "Epoch 183/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 25.8477 - mse: 25.8477\n",
      "Epoch 184/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 24.9846 - mse: 24.9846\n",
      "Epoch 185/200\n",
      "379/379 [==============================] - 0s 536us/step - loss: 26.5635 - mse: 26.5635\n",
      "Epoch 186/200\n",
      "379/379 [==============================] - 0s 522us/step - loss: 26.4423 - mse: 26.4423\n",
      "Epoch 187/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 27.3098 - mse: 27.3098\n",
      "Epoch 188/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 26.2482 - mse: 26.2482\n",
      "Epoch 189/200\n",
      "379/379 [==============================] - 0s 553us/step - loss: 26.6868 - mse: 26.6868\n",
      "Epoch 190/200\n",
      "379/379 [==============================] - 0s 495us/step - loss: 25.7695 - mse: 25.7695\n",
      "Epoch 191/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 27.3181 - mse: 27.3181\n",
      "Epoch 192/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 25.0824 - mse: 25.0824\n",
      "Epoch 193/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 25.4256 - mse: 25.4256\n",
      "Epoch 194/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 26.2608 - mse: 26.2608\n",
      "Epoch 195/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 26.9868 - mse: 26.9867\n",
      "Epoch 196/200\n",
      "379/379 [==============================] - 0s 523us/step - loss: 25.9763 - mse: 25.9763\n",
      "Epoch 197/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 26.6608 - mse: 26.6608\n",
      "Epoch 198/200\n",
      "379/379 [==============================] - 0s 500us/step - loss: 26.7260 - mse: 26.7260\n",
      "Epoch 199/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 26.0594 - mse: 26.0594\n",
      "Epoch 200/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 27.1457 - mse: 27.1457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12acce910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(13,))\n",
    "output = Dense(1)(inp)\n",
    "model = keras.models.Model(input=inp, output=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "379/379 [==============================] - 0s 550us/step - loss: 25.7332 - mse: 25.7332\n",
      "Epoch 2/200\n",
      "379/379 [==============================] - 0s 575us/step - loss: 26.6036 - mse: 26.6036\n",
      "Epoch 3/200\n",
      "379/379 [==============================] - 0s 545us/step - loss: 25.5830 - mse: 25.5830\n",
      "Epoch 4/200\n",
      "379/379 [==============================] - 0s 578us/step - loss: 27.2026 - mse: 27.2026\n",
      "Epoch 5/200\n",
      "379/379 [==============================] - 0s 593us/step - loss: 25.6281 - mse: 25.6281\n",
      "Epoch 6/200\n",
      "379/379 [==============================] - 0s 628us/step - loss: 25.9538 - mse: 25.9538\n",
      "Epoch 7/200\n",
      "379/379 [==============================] - 0s 614us/step - loss: 26.1662 - mse: 26.1662\n",
      "Epoch 8/200\n",
      "379/379 [==============================] - 0s 592us/step - loss: 27.2120 - mse: 27.2120\n",
      "Epoch 9/200\n",
      "379/379 [==============================] - 0s 567us/step - loss: 27.0708 - mse: 27.0708\n",
      "Epoch 10/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 25.4934 - mse: 25.4934\n",
      "Epoch 11/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 26.0751 - mse: 26.0751\n",
      "Epoch 12/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 27.1843 - mse: 27.1843\n",
      "Epoch 13/200\n",
      "379/379 [==============================] - 0s 528us/step - loss: 26.0433 - mse: 26.0433\n",
      "Epoch 14/200\n",
      "379/379 [==============================] - 0s 557us/step - loss: 27.0350 - mse: 27.0350\n",
      "Epoch 15/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 26.2495 - mse: 26.2495\n",
      "Epoch 16/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 25.3407 - mse: 25.3407\n",
      "Epoch 17/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 25.1869 - mse: 25.1869\n",
      "Epoch 18/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 26.9134 - mse: 26.9134\n",
      "Epoch 19/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 26.0318 - mse: 26.0318\n",
      "Epoch 20/200\n",
      "379/379 [==============================] - 0s 522us/step - loss: 26.3162 - mse: 26.3162\n",
      "Epoch 21/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 25.5095 - mse: 25.5095\n",
      "Epoch 22/200\n",
      "379/379 [==============================] - 0s 517us/step - loss: 25.4508 - mse: 25.4508\n",
      "Epoch 23/200\n",
      "379/379 [==============================] - 0s 515us/step - loss: 26.5684 - mse: 26.5684\n",
      "Epoch 24/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 26.4333 - mse: 26.4333\n",
      "Epoch 25/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 26.6792 - mse: 26.6792\n",
      "Epoch 26/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 25.2967 - mse: 25.2967\n",
      "Epoch 27/200\n",
      "379/379 [==============================] - 0s 524us/step - loss: 25.9127 - mse: 25.9127\n",
      "Epoch 28/200\n",
      "379/379 [==============================] - 0s 550us/step - loss: 25.3120 - mse: 25.3120\n",
      "Epoch 29/200\n",
      "379/379 [==============================] - 0s 543us/step - loss: 24.9937 - mse: 24.9937\n",
      "Epoch 30/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 27.3370 - mse: 27.3370\n",
      "Epoch 31/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 26.0849 - mse: 26.0849\n",
      "Epoch 32/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 24.8060 - mse: 24.8060\n",
      "Epoch 33/200\n",
      "379/379 [==============================] - 0s 550us/step - loss: 25.1318 - mse: 25.1318\n",
      "Epoch 34/200\n",
      "379/379 [==============================] - 0s 625us/step - loss: 25.8941 - mse: 25.8941\n",
      "Epoch 35/200\n",
      "379/379 [==============================] - 0s 567us/step - loss: 26.7698 - mse: 26.7698\n",
      "Epoch 36/200\n",
      "379/379 [==============================] - 0s 629us/step - loss: 25.2125 - mse: 25.2125\n",
      "Epoch 37/200\n",
      "379/379 [==============================] - 0s 547us/step - loss: 25.5830 - mse: 25.5830\n",
      "Epoch 38/200\n",
      "379/379 [==============================] - 0s 529us/step - loss: 25.5317 - mse: 25.5317\n",
      "Epoch 39/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 25.2005 - mse: 25.2005\n",
      "Epoch 40/200\n",
      "379/379 [==============================] - 0s 571us/step - loss: 24.7357 - mse: 24.7357\n",
      "Epoch 41/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 26.6102 - mse: 26.6102\n",
      "Epoch 42/200\n",
      "379/379 [==============================] - 0s 601us/step - loss: 25.0162 - mse: 25.0162\n",
      "Epoch 43/200\n",
      "379/379 [==============================] - 0s 565us/step - loss: 25.3662 - mse: 25.3663\n",
      "Epoch 44/200\n",
      "379/379 [==============================] - 0s 554us/step - loss: 24.2236 - mse: 24.2236\n",
      "Epoch 45/200\n",
      "379/379 [==============================] - 0s 553us/step - loss: 24.5866 - mse: 24.5866\n",
      "Epoch 46/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 26.1162 - mse: 26.1162\n",
      "Epoch 47/200\n",
      "379/379 [==============================] - 0s 560us/step - loss: 24.5488 - mse: 24.5488\n",
      "Epoch 48/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 24.8980 - mse: 24.8980\n",
      "Epoch 49/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 25.5678 - mse: 25.5678\n",
      "Epoch 50/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 25.1967 - mse: 25.1967\n",
      "Epoch 51/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 25.4672 - mse: 25.4672\n",
      "Epoch 52/200\n",
      "379/379 [==============================] - 0s 527us/step - loss: 24.4547 - mse: 24.4547\n",
      "Epoch 53/200\n",
      "379/379 [==============================] - 0s 531us/step - loss: 25.9219 - mse: 25.9219\n",
      "Epoch 54/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 24.8627 - mse: 24.8627\n",
      "Epoch 55/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 25.4749 - mse: 25.4749\n",
      "Epoch 56/200\n",
      "379/379 [==============================] - 0s 495us/step - loss: 25.4612 - mse: 25.4612\n",
      "Epoch 57/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 25.1002 - mse: 25.1002\n",
      "Epoch 58/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 25.3713 - mse: 25.3713\n",
      "Epoch 59/200\n",
      "379/379 [==============================] - 0s 493us/step - loss: 24.6082 - mse: 24.6082\n",
      "Epoch 60/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 24.9221 - mse: 24.9221\n",
      "Epoch 61/200\n",
      "379/379 [==============================] - 0s 528us/step - loss: 24.6309 - mse: 24.6309\n",
      "Epoch 62/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 25.1703 - mse: 25.1703\n",
      "Epoch 63/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 26.0665 - mse: 26.0665\n",
      "Epoch 64/200\n",
      "379/379 [==============================] - 0s 524us/step - loss: 25.4111 - mse: 25.4111\n",
      "Epoch 65/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 24.6025 - mse: 24.6025\n",
      "Epoch 66/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 24.6522 - mse: 24.6522\n",
      "Epoch 67/200\n",
      "379/379 [==============================] - 0s 549us/step - loss: 25.1120 - mse: 25.1120\n",
      "Epoch 68/200\n",
      "379/379 [==============================] - 0s 568us/step - loss: 24.8998 - mse: 24.8998\n",
      "Epoch 69/200\n",
      "379/379 [==============================] - 0s 520us/step - loss: 25.3596 - mse: 25.3596\n",
      "Epoch 70/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 24.9877 - mse: 24.9877\n",
      "Epoch 71/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 24.9576 - mse: 24.9576\n",
      "Epoch 72/200\n",
      "379/379 [==============================] - 0s 521us/step - loss: 24.5785 - mse: 24.5785\n",
      "Epoch 73/200\n",
      "379/379 [==============================] - 0s 496us/step - loss: 25.4523 - mse: 25.4523\n",
      "Epoch 74/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 24.6669 - mse: 24.6669\n",
      "Epoch 75/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 24.5352 - mse: 24.5352\n",
      "Epoch 76/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 26.3428 - mse: 26.3428\n",
      "Epoch 77/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 24.4636 - mse: 24.4636\n",
      "Epoch 78/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 25.8366 - mse: 25.8366\n",
      "Epoch 79/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 24.7736 - mse: 24.7736\n",
      "Epoch 80/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 24.3787 - mse: 24.3787\n",
      "Epoch 81/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 25.6637 - mse: 25.6637\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 526us/step - loss: 24.1142 - mse: 24.1142\n",
      "Epoch 83/200\n",
      "379/379 [==============================] - 0s 540us/step - loss: 25.1997 - mse: 25.1997\n",
      "Epoch 84/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 24.7796 - mse: 24.7796\n",
      "Epoch 85/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 24.9636 - mse: 24.9636\n",
      "Epoch 86/200\n",
      "379/379 [==============================] - 0s 497us/step - loss: 24.2685 - mse: 24.2685\n",
      "Epoch 87/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.6342 - mse: 24.6342\n",
      "Epoch 88/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 24.8270 - mse: 24.8270\n",
      "Epoch 89/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 24.7158 - mse: 24.7158\n",
      "Epoch 90/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 25.3372 - mse: 25.3372\n",
      "Epoch 91/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 23.7580 - mse: 23.7580\n",
      "Epoch 92/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 24.3304 - mse: 24.3304\n",
      "Epoch 93/200\n",
      "379/379 [==============================] - 0s 531us/step - loss: 25.0723 - mse: 25.0723\n",
      "Epoch 94/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 25.1939 - mse: 25.1939\n",
      "Epoch 95/200\n",
      "379/379 [==============================] - 0s 500us/step - loss: 24.6665 - mse: 24.6665\n",
      "Epoch 96/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 25.1274 - mse: 25.1275\n",
      "Epoch 97/200\n",
      "379/379 [==============================] - 0s 515us/step - loss: 26.0413 - mse: 26.0413\n",
      "Epoch 98/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 24.7353 - mse: 24.7353\n",
      "Epoch 99/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 24.2578 - mse: 24.2578\n",
      "Epoch 100/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 24.6684 - mse: 24.6684\n",
      "Epoch 101/200\n",
      "379/379 [==============================] - 0s 513us/step - loss: 23.8931 - mse: 23.8931\n",
      "Epoch 102/200\n",
      "379/379 [==============================] - 0s 492us/step - loss: 24.6947 - mse: 24.6947\n",
      "Epoch 103/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 23.9666 - mse: 23.9666\n",
      "Epoch 104/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 24.4817 - mse: 24.4818\n",
      "Epoch 105/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 25.4277 - mse: 25.4277\n",
      "Epoch 106/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.7031 - mse: 24.7031\n",
      "Epoch 107/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 24.9305 - mse: 24.9305\n",
      "Epoch 108/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.1778 - mse: 24.1777\n",
      "Epoch 109/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 24.2018 - mse: 24.2018\n",
      "Epoch 110/200\n",
      "379/379 [==============================] - 0s 504us/step - loss: 24.8107 - mse: 24.8107\n",
      "Epoch 111/200\n",
      "379/379 [==============================] - 0s 572us/step - loss: 24.4616 - mse: 24.4616\n",
      "Epoch 112/200\n",
      "379/379 [==============================] - 0s 611us/step - loss: 25.1011 - mse: 25.1011\n",
      "Epoch 113/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 25.0241 - mse: 25.0241\n",
      "Epoch 114/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 24.7790 - mse: 24.7790\n",
      "Epoch 115/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 24.0176 - mse: 24.0176\n",
      "Epoch 116/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 24.2869 - mse: 24.2869\n",
      "Epoch 117/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 25.1664 - mse: 25.1664\n",
      "Epoch 118/200\n",
      "379/379 [==============================] - 0s 507us/step - loss: 24.7596 - mse: 24.7596\n",
      "Epoch 119/200\n",
      "379/379 [==============================] - 0s 538us/step - loss: 24.9558 - mse: 24.9558\n",
      "Epoch 120/200\n",
      "379/379 [==============================] - 0s 548us/step - loss: 24.7753 - mse: 24.7753\n",
      "Epoch 121/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 24.9429 - mse: 24.9429\n",
      "Epoch 122/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 24.4308 - mse: 24.4308\n",
      "Epoch 123/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 24.1084 - mse: 24.1084\n",
      "Epoch 124/200\n",
      "379/379 [==============================] - 0s 509us/step - loss: 24.2747 - mse: 24.2747\n",
      "Epoch 125/200\n",
      "379/379 [==============================] - 0s 523us/step - loss: 23.0482 - mse: 23.0482\n",
      "Epoch 126/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 26.2173 - mse: 26.2174\n",
      "Epoch 127/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 24.8124 - mse: 24.8124\n",
      "Epoch 128/200\n",
      "379/379 [==============================] - 0s 508us/step - loss: 23.6819 - mse: 23.6819\n",
      "Epoch 129/200\n",
      "379/379 [==============================] - 0s 617us/step - loss: 25.6277 - mse: 25.6277 0s - loss: 26.9630 - mse: 26.963\n",
      "Epoch 130/200\n",
      "379/379 [==============================] - 0s 538us/step - loss: 24.8754 - mse: 24.8754\n",
      "Epoch 131/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 24.0674 - mse: 24.0674\n",
      "Epoch 132/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 24.8334 - mse: 24.8333\n",
      "Epoch 133/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 22.5640 - mse: 22.5641\n",
      "Epoch 134/200\n",
      "379/379 [==============================] - 0s 670us/step - loss: 23.7973 - mse: 23.7973\n",
      "Epoch 135/200\n",
      "379/379 [==============================] - 0s 556us/step - loss: 24.5231 - mse: 24.5231\n",
      "Epoch 136/200\n",
      "379/379 [==============================] - 0s 527us/step - loss: 24.3507 - mse: 24.3507\n",
      "Epoch 137/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 24.2543 - mse: 24.2543\n",
      "Epoch 138/200\n",
      "379/379 [==============================] - 0s 517us/step - loss: 24.0871 - mse: 24.0872\n",
      "Epoch 139/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 24.1890 - mse: 24.1890\n",
      "Epoch 140/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 25.4182 - mse: 25.4182\n",
      "Epoch 141/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 24.7334 - mse: 24.7334\n",
      "Epoch 142/200\n",
      "379/379 [==============================] - 0s 547us/step - loss: 24.8599 - mse: 24.8599\n",
      "Epoch 143/200\n",
      "379/379 [==============================] - 0s 615us/step - loss: 23.9320 - mse: 23.9321\n",
      "Epoch 144/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 24.4167 - mse: 24.4167\n",
      "Epoch 145/200\n",
      "379/379 [==============================] - 0s 526us/step - loss: 23.8300 - mse: 23.8300\n",
      "Epoch 146/200\n",
      "379/379 [==============================] - 0s 499us/step - loss: 22.9840 - mse: 22.9840\n",
      "Epoch 147/200\n",
      "379/379 [==============================] - 0s 521us/step - loss: 24.8960 - mse: 24.8960\n",
      "Epoch 148/200\n",
      "379/379 [==============================] - 0s 524us/step - loss: 26.3472 - mse: 26.3472\n",
      "Epoch 149/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 24.8723 - mse: 24.8723\n",
      "Epoch 150/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 25.1804 - mse: 25.1804\n",
      "Epoch 151/200\n",
      "379/379 [==============================] - 0s 498us/step - loss: 24.3977 - mse: 24.3977\n",
      "Epoch 152/200\n",
      "379/379 [==============================] - 0s 496us/step - loss: 24.5713 - mse: 24.5713\n",
      "Epoch 153/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.5319 - mse: 24.5319\n",
      "Epoch 154/200\n",
      "379/379 [==============================] - 0s 519us/step - loss: 24.5034 - mse: 24.5034\n",
      "Epoch 155/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 24.5689 - mse: 24.5689\n",
      "Epoch 156/200\n",
      "379/379 [==============================] - 0s 496us/step - loss: 23.5400 - mse: 23.5400\n",
      "Epoch 157/200\n",
      "379/379 [==============================] - 0s 607us/step - loss: 23.7941 - mse: 23.7941\n",
      "Epoch 158/200\n",
      "379/379 [==============================] - 0s 518us/step - loss: 25.4929 - mse: 25.4929\n",
      "Epoch 159/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 24.5631 - mse: 24.5631\n",
      "Epoch 160/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.5851 - mse: 24.5851\n",
      "Epoch 161/200\n",
      "379/379 [==============================] - 0s 497us/step - loss: 23.2051 - mse: 23.2051\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 526us/step - loss: 24.2790 - mse: 24.2790\n",
      "Epoch 163/200\n",
      "379/379 [==============================] - 0s 502us/step - loss: 23.9992 - mse: 23.9992\n",
      "Epoch 164/200\n",
      "379/379 [==============================] - 0s 526us/step - loss: 25.2181 - mse: 25.2181\n",
      "Epoch 165/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 25.0245 - mse: 25.0246\n",
      "Epoch 166/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 24.6681 - mse: 24.6681\n",
      "Epoch 167/200\n",
      "379/379 [==============================] - 0s 515us/step - loss: 24.1548 - mse: 24.1548\n",
      "Epoch 168/200\n",
      "379/379 [==============================] - 0s 525us/step - loss: 25.0535 - mse: 25.0535\n",
      "Epoch 169/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 24.5951 - mse: 24.5951\n",
      "Epoch 170/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.3871 - mse: 24.3871\n",
      "Epoch 171/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 24.1887 - mse: 24.1887\n",
      "Epoch 172/200\n",
      "379/379 [==============================] - 0s 505us/step - loss: 23.5662 - mse: 23.5662\n",
      "Epoch 173/200\n",
      "379/379 [==============================] - 0s 540us/step - loss: 26.0924 - mse: 26.0924\n",
      "Epoch 174/200\n",
      "379/379 [==============================] - 0s 523us/step - loss: 24.4268 - mse: 24.4268\n",
      "Epoch 175/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.3710 - mse: 24.3710\n",
      "Epoch 176/200\n",
      "379/379 [==============================] - 0s 510us/step - loss: 24.1118 - mse: 24.1118\n",
      "Epoch 177/200\n",
      "379/379 [==============================] - 0s 538us/step - loss: 25.2463 - mse: 25.2463\n",
      "Epoch 178/200\n",
      "379/379 [==============================] - 0s 574us/step - loss: 23.1220 - mse: 23.1220\n",
      "Epoch 179/200\n",
      "379/379 [==============================] - 0s 512us/step - loss: 23.7475 - mse: 23.7475\n",
      "Epoch 180/200\n",
      "379/379 [==============================] - 0s 511us/step - loss: 23.9835 - mse: 23.9835\n",
      "Epoch 181/200\n",
      "379/379 [==============================] - 0s 552us/step - loss: 24.0406 - mse: 24.0406\n",
      "Epoch 182/200\n",
      "379/379 [==============================] - 0s 506us/step - loss: 24.6087 - mse: 24.6087\n",
      "Epoch 183/200\n",
      "379/379 [==============================] - 0s 514us/step - loss: 24.0944 - mse: 24.0944\n",
      "Epoch 184/200\n",
      "379/379 [==============================] - 0s 539us/step - loss: 24.8038 - mse: 24.8038\n",
      "Epoch 185/200\n",
      "379/379 [==============================] - 0s 516us/step - loss: 24.9390 - mse: 24.9390\n",
      "Epoch 186/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 24.7623 - mse: 24.7623\n",
      "Epoch 187/200\n",
      "379/379 [==============================] - 0s 538us/step - loss: 24.6752 - mse: 24.6752\n",
      "Epoch 188/200\n",
      "379/379 [==============================] - 0s 501us/step - loss: 23.7138 - mse: 23.7139\n",
      "Epoch 189/200\n",
      "379/379 [==============================] - 0s 537us/step - loss: 23.6153 - mse: 23.6153\n",
      "Epoch 190/200\n",
      "379/379 [==============================] - 0s 608us/step - loss: 24.3659 - mse: 24.3659\n",
      "Epoch 191/200\n",
      "379/379 [==============================] - 0s 530us/step - loss: 25.0224 - mse: 25.0225\n",
      "Epoch 192/200\n",
      "379/379 [==============================] - 0s 548us/step - loss: 24.3570 - mse: 24.3571\n",
      "Epoch 193/200\n",
      "379/379 [==============================] - 0s 578us/step - loss: 23.9638 - mse: 23.9638\n",
      "Epoch 194/200\n",
      "379/379 [==============================] - 0s 540us/step - loss: 24.1384 - mse: 24.1384\n",
      "Epoch 195/200\n",
      "379/379 [==============================] - 0s 533us/step - loss: 23.9934 - mse: 23.9934\n",
      "Epoch 196/200\n",
      "379/379 [==============================] - 0s 581us/step - loss: 25.0136 - mse: 25.0136\n",
      "Epoch 197/200\n",
      "379/379 [==============================] - 0s 517us/step - loss: 24.2879 - mse: 24.2879\n",
      "Epoch 198/200\n",
      "379/379 [==============================] - 0s 522us/step - loss: 25.0794 - mse: 25.0794\n",
      "Epoch 199/200\n",
      "379/379 [==============================] - 0s 583us/step - loss: 25.2100 - mse: 25.2100\n",
      "Epoch 200/200\n",
      "379/379 [==============================] - 0s 503us/step - loss: 24.2429 - mse: 24.2429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1497e9110>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 238us/step\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "pima = pd.read_csv('diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "X = pima[feature_cols]\n",
    "y = pima['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(y_test)\n",
    "y_pred = list(y_pred)\n",
    "def confusion(yt, yp):\n",
    "    ma = np.zeros((2,2))\n",
    "    for i in range(len(yt)):\n",
    "        if yt[i] == yp[i] and yp[i] == 0:\n",
    "            ma[0][0] += 1\n",
    "        elif yt[i] == yp[i] and yp[i] == 1:\n",
    "            ma[1][1] += 1\n",
    "        elif yt[i] != yp[i] and yp[i] == 0:\n",
    "            ma[1][0] += 1\n",
    "        elif yt[i] != yp[i] and yp[i] == 1:\n",
    "            ma[0][1] += 1\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118.  12.]\n",
      " [ 47.  15.]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnminer/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "576/576 [==============================] - 0s 631us/step - loss: 4298.0836 - mse: 4298.0791\n",
      "Epoch 2/12\n",
      "576/576 [==============================] - 0s 504us/step - loss: 1964.5310 - mse: 1964.5321\n",
      "Epoch 3/12\n",
      "576/576 [==============================] - 0s 502us/step - loss: 1044.5243 - mse: 1044.5238\n",
      "Epoch 4/12\n",
      "576/576 [==============================] - 0s 494us/step - loss: 590.3631 - mse: 590.3629\n",
      "Epoch 5/12\n",
      "576/576 [==============================] - 0s 505us/step - loss: 336.6076 - mse: 336.6075\n",
      "Epoch 6/12\n",
      "576/576 [==============================] - 0s 534us/step - loss: 203.5441 - mse: 203.5441\n",
      "Epoch 7/12\n",
      "576/576 [==============================] - 0s 539us/step - loss: 137.0325 - mse: 137.0324\n",
      "Epoch 8/12\n",
      "576/576 [==============================] - 0s 546us/step - loss: 102.0529 - mse: 102.0529\n",
      "Epoch 9/12\n",
      "576/576 [==============================] - 0s 502us/step - loss: 79.6760 - mse: 79.6760\n",
      "Epoch 10/12\n",
      "576/576 [==============================] - 0s 515us/step - loss: 61.4017 - mse: 61.4018\n",
      "Epoch 11/12\n",
      "576/576 [==============================] - 0s 534us/step - loss: 46.0873 - mse: 46.0872\n",
      "Epoch 12/12\n",
      "576/576 [==============================] - 0s 512us/step - loss: 33.3729 - mse: 33.3729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14c241390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(4,))\n",
    "output = Dense(1)(inp)\n",
    "model = keras.models.Model(input=inp, output=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\"mse\"])\n",
    "model.fit(X_train, y_train, epochs=12, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 553us/step - loss: 22.7127 - mse: 22.7127\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 525us/step - loss: 14.9239 - mse: 14.9239\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 532us/step - loss: 9.2947 - mse: 9.2947\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 517us/step - loss: 5.5005 - mse: 5.5005\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 622us/step - loss: 3.1134 - mse: 3.1134\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 626us/step - loss: 1.7148 - mse: 1.7148\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 512us/step - loss: 0.9874 - mse: 0.9874\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 507us/step - loss: 0.5432 - mse: 0.5432\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 513us/step - loss: 0.3515 - mse: 0.3515\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 600us/step - loss: 0.2618 - mse: 0.2618\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 526us/step - loss: 0.2335 - mse: 0.2335\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 517us/step - loss: 0.2206 - mse: 0.2206\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 605us/step - loss: 0.2535 - mse: 0.2535\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 621us/step - loss: 0.2477 - mse: 0.2477\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 602us/step - loss: 0.3128 - mse: 0.3128\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 515us/step - loss: 0.3235 - mse: 0.3235\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 520us/step - loss: 0.2468 - mse: 0.2468\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 573us/step - loss: 0.2403 - mse: 0.2403\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 621us/step - loss: 0.2677 - mse: 0.2677\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 549us/step - loss: 0.2392 - mse: 0.2392\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 552us/step - loss: 0.2376 - mse: 0.2376\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 628us/step - loss: 0.2614 - mse: 0.2614\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 543us/step - loss: 0.2623 - mse: 0.2623\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 587us/step - loss: 0.2445 - mse: 0.2445\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 654us/step - loss: 0.2841 - mse: 0.2841\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 677us/step - loss: 0.2443 - mse: 0.2443\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 593us/step - loss: 0.2642 - mse: 0.2642\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 539us/step - loss: 0.2472 - mse: 0.2472\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 628us/step - loss: 0.2396 - mse: 0.2396\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 647us/step - loss: 0.2515 - mse: 0.2515\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 539us/step - loss: 0.2404 - mse: 0.2404\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 535us/step - loss: 0.2921 - mse: 0.2921\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 563us/step - loss: 0.2386 - mse: 0.2386\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 536us/step - loss: 0.2497 - mse: 0.2497\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 612us/step - loss: 0.2529 - mse: 0.2529\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 585us/step - loss: 0.2618 - mse: 0.2618\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 509us/step - loss: 0.3034 - mse: 0.3034\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 521us/step - loss: 0.2391 - mse: 0.2391\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 521us/step - loss: 0.2420 - mse: 0.2420\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 615us/step - loss: 0.2609 - mse: 0.2609\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 639us/step - loss: 0.2667 - mse: 0.2667\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 521us/step - loss: 0.2448 - mse: 0.2448\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 511us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 563us/step - loss: 0.2340 - mse: 0.2340\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 594us/step - loss: 0.2479 - mse: 0.2479\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 507us/step - loss: 0.3772 - mse: 0.3772\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 511us/step - loss: 0.2417 - mse: 0.2417\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 515us/step - loss: 0.2441 - mse: 0.2441\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 605us/step - loss: 0.2360 - mse: 0.2360\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 537us/step - loss: 0.3093 - mse: 0.3093\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 520us/step - loss: 0.2692 - mse: 0.2692\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 561us/step - loss: 0.2676 - mse: 0.2676\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 639us/step - loss: 0.2417 - mse: 0.2417\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 512us/step - loss: 0.2566 - mse: 0.2566\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 517us/step - loss: 0.2432 - mse: 0.2432\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 509us/step - loss: 0.2874 - mse: 0.2874\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 563us/step - loss: 0.4627 - mse: 0.4627\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 581us/step - loss: 0.2290 - mse: 0.2290\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 503us/step - loss: 0.2323 - mse: 0.2323\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 506us/step - loss: 0.2190 - mse: 0.2190\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 528us/step - loss: 0.2448 - mse: 0.2448\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 508us/step - loss: 0.2771 - mse: 0.2771\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 517us/step - loss: 0.3793 - mse: 0.3793\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 546us/step - loss: 0.2244 - mse: 0.2244\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 529us/step - loss: 0.2410 - mse: 0.2410\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 531us/step - loss: 0.2688 - mse: 0.2688\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 540us/step - loss: 0.2669 - mse: 0.2669\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 519us/step - loss: 0.2515 - mse: 0.2515\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 575us/step - loss: 0.3138 - mse: 0.3138\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 519us/step - loss: 0.2495 - mse: 0.2495\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 546us/step - loss: 0.2523 - mse: 0.2523\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 536us/step - loss: 0.2277 - mse: 0.2277\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 530us/step - loss: 0.2569 - mse: 0.2569\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 514us/step - loss: 0.2596 - mse: 0.2596\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 521us/step - loss: 0.2444 - mse: 0.2444\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 506us/step - loss: 0.2293 - mse: 0.2293\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 512us/step - loss: 0.2743 - mse: 0.2743\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 528us/step - loss: 0.2467 - mse: 0.2467\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 500us/step - loss: 0.2548 - mse: 0.2548\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 527us/step - loss: 0.2700 - mse: 0.2700\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 503us/step - loss: 0.3450 - mse: 0.3450\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 522us/step - loss: 0.2473 - mse: 0.2473\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 552us/step - loss: 0.2291 - mse: 0.2291\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 541us/step - loss: 0.2455 - mse: 0.2455\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 541us/step - loss: 0.2644 - mse: 0.2644\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 516us/step - loss: 0.2591 - mse: 0.2591\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 521us/step - loss: 0.2731 - mse: 0.2731\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 504us/step - loss: 0.2600 - mse: 0.2600\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 516us/step - loss: 0.2275 - mse: 0.2275\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 501us/step - loss: 0.2461 - mse: 0.2461\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 523us/step - loss: 0.2412 - mse: 0.2412\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 524us/step - loss: 0.2959 - mse: 0.2959\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 510us/step - loss: 0.2450 - mse: 0.2450\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 524us/step - loss: 0.2356 - mse: 0.2356\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 515us/step - loss: 0.2850 - mse: 0.2850\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 504us/step - loss: 0.2401 - mse: 0.2401\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 507us/step - loss: 0.2643 - mse: 0.2643\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 558us/step - loss: 0.2402 - mse: 0.2402\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 496us/step - loss: 0.2832 - mse: 0.2832\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 506us/step - loss: 0.2536 - mse: 0.2536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14c373e90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129.   1.]\n",
      " [ 56.   6.]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion(y_test, [1 if i >= 0.90 else 0 for i in y_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32557607],\n",
       "       [ 0.37258834],\n",
       "       [ 0.24573225],\n",
       "       [ 0.62197214],\n",
       "       [ 0.08149844],\n",
       "       [ 0.14763182],\n",
       "       [ 0.6767823 ],\n",
       "       [ 0.6886373 ],\n",
       "       [ 0.5993183 ],\n",
       "       [ 0.88277453],\n",
       "       [ 0.64500827],\n",
       "       [ 0.97931474],\n",
       "       [ 0.3432216 ],\n",
       "       [ 0.33115858],\n",
       "       [ 0.39170069],\n",
       "       [ 0.13218516],\n",
       "       [ 0.5881848 ],\n",
       "       [-0.00219673],\n",
       "       [ 0.4223187 ],\n",
       "       [ 0.44146556],\n",
       "       [ 0.40451342],\n",
       "       [ 0.3323722 ],\n",
       "       [ 0.13559955],\n",
       "       [ 0.38919288],\n",
       "       [ 0.2541324 ],\n",
       "       [ 0.20400685],\n",
       "       [-0.047144  ],\n",
       "       [ 0.82452196],\n",
       "       [ 0.06558126],\n",
       "       [ 0.16679496],\n",
       "       [ 0.5829057 ],\n",
       "       [ 0.40435708],\n",
       "       [ 0.31288862],\n",
       "       [ 0.55230635],\n",
       "       [ 0.09592575],\n",
       "       [ 0.3570487 ],\n",
       "       [ 0.6024062 ],\n",
       "       [ 0.17194605],\n",
       "       [ 0.33859897],\n",
       "       [ 0.36189443],\n",
       "       [ 0.35150504],\n",
       "       [ 0.34313697],\n",
       "       [ 0.30451512],\n",
       "       [ 0.24624419],\n",
       "       [ 1.3165178 ],\n",
       "       [-0.38670558],\n",
       "       [ 0.14559788],\n",
       "       [ 0.33288693],\n",
       "       [ 0.43970877],\n",
       "       [ 0.23272711],\n",
       "       [ 0.29598206],\n",
       "       [ 0.2826848 ],\n",
       "       [ 1.052784  ],\n",
       "       [ 0.3561421 ],\n",
       "       [ 0.6537071 ],\n",
       "       [ 0.03238034],\n",
       "       [ 0.12770444],\n",
       "       [ 0.5857634 ],\n",
       "       [ 0.12121826],\n",
       "       [-0.18212253],\n",
       "       [ 0.8948677 ],\n",
       "       [ 0.81085235],\n",
       "       [ 0.01120299],\n",
       "       [ 0.22683752],\n",
       "       [ 0.20412427],\n",
       "       [ 0.27185994],\n",
       "       [ 0.43024653],\n",
       "       [ 0.16239893],\n",
       "       [ 0.3927998 ],\n",
       "       [ 0.37048107],\n",
       "       [ 0.13744527],\n",
       "       [ 0.23221517],\n",
       "       [ 0.21878272],\n",
       "       [ 0.52706414],\n",
       "       [ 0.40757555],\n",
       "       [ 0.2365784 ],\n",
       "       [ 0.598082  ],\n",
       "       [ 0.63767284],\n",
       "       [ 0.23473263],\n",
       "       [ 0.30577487],\n",
       "       [ 0.4996354 ],\n",
       "       [ 0.6096899 ],\n",
       "       [ 0.42593294],\n",
       "       [ 0.06451374],\n",
       "       [ 0.2898577 ],\n",
       "       [ 0.40659398],\n",
       "       [ 0.07485247],\n",
       "       [ 0.55691046],\n",
       "       [ 0.84251446],\n",
       "       [ 0.51606745],\n",
       "       [ 0.13984543],\n",
       "       [ 0.13548213],\n",
       "       [ 0.30855852],\n",
       "       [ 0.09103602],\n",
       "       [ 0.48189515],\n",
       "       [ 0.21496814],\n",
       "       [ 0.60902935],\n",
       "       [ 0.8027697 ],\n",
       "       [ 0.8821873 ],\n",
       "       [ 0.31457645],\n",
       "       [ 0.86910087],\n",
       "       [ 0.20268089],\n",
       "       [ 0.3396802 ],\n",
       "       [ 0.03854179],\n",
       "       [ 0.30722606],\n",
       "       [ 0.3028205 ],\n",
       "       [ 0.26548463],\n",
       "       [ 0.15532565],\n",
       "       [ 0.14330572],\n",
       "       [ 0.1796403 ],\n",
       "       [ 0.13407755],\n",
       "       [ 0.7053805 ],\n",
       "       [ 0.4312281 ],\n",
       "       [ 0.3309576 ],\n",
       "       [ 1.070163  ],\n",
       "       [ 0.38789183],\n",
       "       [ 0.5443528 ],\n",
       "       [ 0.72479814],\n",
       "       [ 0.12656313],\n",
       "       [ 0.9062163 ],\n",
       "       [ 0.42620277],\n",
       "       [ 0.6311149 ],\n",
       "       [ 0.5652835 ],\n",
       "       [ 0.5028574 ],\n",
       "       [ 0.1565035 ],\n",
       "       [ 0.04860741],\n",
       "       [ 0.5476237 ],\n",
       "       [ 0.30423898],\n",
       "       [ 0.35222536],\n",
       "       [ 0.01736969],\n",
       "       [ 0.425834  ],\n",
       "       [-0.26722655],\n",
       "       [ 0.11626798],\n",
       "       [ 1.3777058 ],\n",
       "       [ 0.5302331 ],\n",
       "       [ 0.4489488 ],\n",
       "       [ 0.14070958],\n",
       "       [ 0.41299552],\n",
       "       [ 0.18168819],\n",
       "       [ 0.11615056],\n",
       "       [ 0.2881567 ],\n",
       "       [ 0.5098488 ],\n",
       "       [ 0.01874578],\n",
       "       [ 0.38018912],\n",
       "       [ 0.3906017 ],\n",
       "       [ 0.03646642],\n",
       "       [ 0.18142003],\n",
       "       [ 0.26310068],\n",
       "       [ 0.07265449],\n",
       "       [ 0.5771889 ],\n",
       "       [ 0.25349504],\n",
       "       [ 0.3852569 ],\n",
       "       [ 0.28494787],\n",
       "       [ 0.28906733],\n",
       "       [ 0.7368776 ],\n",
       "       [ 0.13072431],\n",
       "       [ 1.6646626 ],\n",
       "       [ 0.28475958],\n",
       "       [ 0.33071887],\n",
       "       [ 0.74630564],\n",
       "       [ 0.5827789 ],\n",
       "       [ 0.34903616],\n",
       "       [ 0.09660631],\n",
       "       [ 0.3147202 ],\n",
       "       [ 0.43366092],\n",
       "       [ 0.15681922],\n",
       "       [ 0.46733147],\n",
       "       [ 0.07772219],\n",
       "       [ 0.18589169],\n",
       "       [ 0.26990634],\n",
       "       [ 0.11904329],\n",
       "       [ 0.50936145],\n",
       "       [ 0.2599538 ],\n",
       "       [ 0.41461605],\n",
       "       [ 0.4792145 ],\n",
       "       [ 0.36423773],\n",
       "       [ 0.5768867 ],\n",
       "       [ 0.43439776],\n",
       "       [ 0.34555405],\n",
       "       [ 0.09768313],\n",
       "       [ 0.30125183],\n",
       "       [ 0.64194506],\n",
       "       [ 0.37160724],\n",
       "       [ 0.31866258],\n",
       "       [ 0.17905325],\n",
       "       [ 0.19382912],\n",
       "       [ 0.3451848 ],\n",
       "       [ 0.19936645],\n",
       "       [ 0.41622943],\n",
       "       [ 0.35615796],\n",
       "       [ 0.23965025],\n",
       "       [ 0.2429049 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
