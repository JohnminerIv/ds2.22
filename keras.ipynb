{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "\n",
    "y_train_one_hot = np_utils.to_categorical(y_train)\n",
    "y_test_one_hot = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnminer/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, input_dim=4, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/johnminer/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 1ms/step - loss: 1.1027 - accuracy: 0.2571\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 599us/step - loss: 1.0887 - accuracy: 0.3619\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 648us/step - loss: 1.0739 - accuracy: 0.3619\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 665us/step - loss: 1.0477 - accuracy: 0.5143\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 657us/step - loss: 1.0059 - accuracy: 0.4571\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 669us/step - loss: 0.9503 - accuracy: 0.7048\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 647us/step - loss: 0.8873 - accuracy: 0.7238\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 664us/step - loss: 0.8174 - accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 656us/step - loss: 0.7505 - accuracy: 0.6952\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 677us/step - loss: 0.6917 - accuracy: 0.8476\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 672us/step - loss: 0.6413 - accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 695us/step - loss: 0.6017 - accuracy: 0.8095\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 647us/step - loss: 0.5666 - accuracy: 0.8952\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 637us/step - loss: 0.5375 - accuracy: 0.8667\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 659us/step - loss: 0.5134 - accuracy: 0.9810\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 647us/step - loss: 0.4920 - accuracy: 0.8857\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 674us/step - loss: 0.4762 - accuracy: 0.9619\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 660us/step - loss: 0.4553 - accuracy: 0.9524\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 678us/step - loss: 0.4403 - accuracy: 0.9619\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 644us/step - loss: 0.4236 - accuracy: 0.9810\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 661us/step - loss: 0.4087 - accuracy: 0.9810\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 674us/step - loss: 0.3934 - accuracy: 0.9810\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 674us/step - loss: 0.3785 - accuracy: 0.9714\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 658us/step - loss: 0.3680 - accuracy: 0.9429\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 666us/step - loss: 0.3520 - accuracy: 0.9810\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 716us/step - loss: 0.3381 - accuracy: 0.9714\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 749us/step - loss: 0.3254 - accuracy: 0.9810\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.3125 - accuracy: 0.9714\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 734us/step - loss: 0.3038 - accuracy: 0.9714\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 711us/step - loss: 0.2894 - accuracy: 0.9619\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.2788 - accuracy: 0.9810\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 706us/step - loss: 0.2718 - accuracy: 0.9810\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 746us/step - loss: 0.2584 - accuracy: 0.9810\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 747us/step - loss: 0.2512 - accuracy: 0.9810\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 720us/step - loss: 0.2409 - accuracy: 0.9714\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 750us/step - loss: 0.2361 - accuracy: 0.9619\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 771us/step - loss: 0.2242 - accuracy: 0.9810\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 698us/step - loss: 0.2171 - accuracy: 0.9905\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 725us/step - loss: 0.2101 - accuracy: 0.9810\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 759us/step - loss: 0.2050 - accuracy: 0.9714\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 754us/step - loss: 0.1957 - accuracy: 0.9714\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 721us/step - loss: 0.1909 - accuracy: 0.9619\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 725us/step - loss: 0.1829 - accuracy: 0.9619\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 722us/step - loss: 0.1827 - accuracy: 0.9714\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 735us/step - loss: 0.1741 - accuracy: 0.9714\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 701us/step - loss: 0.1680 - accuracy: 0.9714\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 761us/step - loss: 0.1653 - accuracy: 0.9714\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 768us/step - loss: 0.1601 - accuracy: 0.9714\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 894us/step - loss: 0.1564 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 961us/step - loss: 0.1510 - accuracy: 0.9714\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 716us/step - loss: 0.1491 - accuracy: 0.9619\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 613us/step - loss: 0.1460 - accuracy: 0.9810\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 540us/step - loss: 0.1406 - accuracy: 0.9810\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 578us/step - loss: 0.1377 - accuracy: 0.9714\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 566us/step - loss: 0.1327 - accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 545us/step - loss: 0.1304 - accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 597us/step - loss: 0.1271 - accuracy: 0.9714\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 607us/step - loss: 0.1241 - accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 593us/step - loss: 0.1255 - accuracy: 0.9619\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 604us/step - loss: 0.1203 - accuracy: 0.9714\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.1171 - accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 623us/step - loss: 0.1158 - accuracy: 0.9714\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 559us/step - loss: 0.1124 - accuracy: 0.9619\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 561us/step - loss: 0.1138 - accuracy: 0.9714\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 543us/step - loss: 0.1090 - accuracy: 0.9714\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 536us/step - loss: 0.1078 - accuracy: 0.9810\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 545us/step - loss: 0.1039 - accuracy: 0.9810\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 539us/step - loss: 0.1059 - accuracy: 0.9714\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 634us/step - loss: 0.1004 - accuracy: 0.9619\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 641us/step - loss: 0.1019 - accuracy: 0.9810\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 642us/step - loss: 0.0990 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 543us/step - loss: 0.0971 - accuracy: 0.9810\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 539us/step - loss: 0.0984 - accuracy: 0.9619\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 542us/step - loss: 0.0945 - accuracy: 0.9810\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 650us/step - loss: 0.0937 - accuracy: 0.9714\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 635us/step - loss: 0.0947 - accuracy: 0.9714\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 612us/step - loss: 0.0919 - accuracy: 0.9619\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 537us/step - loss: 0.0891 - accuracy: 0.9714\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 524us/step - loss: 0.0873 - accuracy: 0.9714\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 538us/step - loss: 0.0872 - accuracy: 0.9619\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 540us/step - loss: 0.0894 - accuracy: 0.9714\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 523us/step - loss: 0.0852 - accuracy: 0.9810\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 536us/step - loss: 0.0874 - accuracy: 0.9714\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 535us/step - loss: 0.0844 - accuracy: 0.9619\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 535us/step - loss: 0.0816 - accuracy: 0.9810\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 525us/step - loss: 0.0797 - accuracy: 0.9714\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 521us/step - loss: 0.0827 - accuracy: 0.9714\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 530us/step - loss: 0.0791 - accuracy: 0.9714\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 523us/step - loss: 0.0790 - accuracy: 0.9714\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 547us/step - loss: 0.0777 - accuracy: 0.9714\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 643us/step - loss: 0.0770 - accuracy: 0.9810\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 662us/step - loss: 0.0780 - accuracy: 0.9810\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 653us/step - loss: 0.0764 - accuracy: 0.9810\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 620us/step - loss: 0.0789 - accuracy: 0.9714\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 643us/step - loss: 0.0764 - accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 652us/step - loss: 0.0751 - accuracy: 0.9619\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 662us/step - loss: 0.0738 - accuracy: 0.9810\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 644us/step - loss: 0.0740 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 586us/step - loss: 0.0730 - accuracy: 0.9619\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 538us/step - loss: 0.0764 - accuracy: 0.9714\n",
      "45/45 [==============================] - 0s 492us/step\n",
      "Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, input_dim=4, init='uniform'))\n",
    "model.add(keras.layers.Activation('sigmoid'))\n",
    "model.add(keras.layers.Dense(3, init='uniform'))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train_one_hot, epochs=100, batch_size=1, verbose=1);\n",
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=1)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnminer/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(16, input_dim=4, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/Users/johnminer/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.0985 - accuracy: 0.3619\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 735us/step - loss: 1.0893 - accuracy: 0.3714\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 682us/step - loss: 1.0733 - accuracy: 0.4190\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 702us/step - loss: 1.0468 - accuracy: 0.5143\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 669us/step - loss: 1.0092 - accuracy: 0.4190\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 664us/step - loss: 0.9578 - accuracy: 0.8190\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 686us/step - loss: 0.8946 - accuracy: 0.7429\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 694us/step - loss: 0.8285 - accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 685us/step - loss: 0.7608 - accuracy: 0.8667\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 704us/step - loss: 0.7025 - accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 670us/step - loss: 0.6516 - accuracy: 0.7905\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 743us/step - loss: 0.6112 - accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 763us/step - loss: 0.5764 - accuracy: 0.9048\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 723us/step - loss: 0.5477 - accuracy: 0.9048\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 711us/step - loss: 0.5238 - accuracy: 0.9714\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 704us/step - loss: 0.5033 - accuracy: 0.9429\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 741us/step - loss: 0.4847 - accuracy: 0.9619\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 687us/step - loss: 0.4676 - accuracy: 0.9810\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 692us/step - loss: 0.4523 - accuracy: 0.9714\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 683us/step - loss: 0.4373 - accuracy: 0.9714\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 745us/step - loss: 0.4247 - accuracy: 0.9810\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 700us/step - loss: 0.4104 - accuracy: 0.9810\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 689us/step - loss: 0.3972 - accuracy: 0.9810\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 706us/step - loss: 0.3835 - accuracy: 0.9714\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 814us/step - loss: 0.3707 - accuracy: 0.9429\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 905us/step - loss: 0.3582 - accuracy: 0.9810\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 872us/step - loss: 0.3495 - accuracy: 0.9714\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 920us/step - loss: 0.3361 - accuracy: 0.9714\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 762us/step - loss: 0.3238 - accuracy: 0.9810\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 774us/step - loss: 0.3119 - accuracy: 0.9810\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 710us/step - loss: 0.3016 - accuracy: 0.9714\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 703us/step - loss: 0.2905 - accuracy: 0.9810\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 688us/step - loss: 0.2836 - accuracy: 0.9619\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 752us/step - loss: 0.2719 - accuracy: 0.9810\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 749us/step - loss: 0.2653 - accuracy: 0.9619\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 659us/step - loss: 0.2546 - accuracy: 0.9714\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 689us/step - loss: 0.2436 - accuracy: 0.9810\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 682us/step - loss: 0.2408 - accuracy: 0.9619\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 678us/step - loss: 0.2317 - accuracy: 0.9810\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 707us/step - loss: 0.2275 - accuracy: 0.9619\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 767us/step - loss: 0.2159 - accuracy: 0.9810\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 731us/step - loss: 0.2086 - accuracy: 0.9810\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 770us/step - loss: 0.2048 - accuracy: 0.9619\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 729us/step - loss: 0.1987 - accuracy: 0.9714\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.1897 - accuracy: 0.9714\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 717us/step - loss: 0.1875 - accuracy: 0.9810\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 709us/step - loss: 0.1815 - accuracy: 0.9810\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 708us/step - loss: 0.1753 - accuracy: 0.9714\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 681us/step - loss: 0.1712 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 799us/step - loss: 0.1674 - accuracy: 0.9714\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 781us/step - loss: 0.1618 - accuracy: 0.9810\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 673us/step - loss: 0.1578 - accuracy: 0.9810\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 661us/step - loss: 0.1536 - accuracy: 0.9714\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 673us/step - loss: 0.1502 - accuracy: 0.9619\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.1475 - accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 709us/step - loss: 0.1441 - accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 813us/step - loss: 0.1392 - accuracy: 0.9714\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 712us/step - loss: 0.1347 - accuracy: 0.9810\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 640us/step - loss: 0.1361 - accuracy: 0.9714\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 657us/step - loss: 0.1311 - accuracy: 0.9619\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 682us/step - loss: 0.1285 - accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 673us/step - loss: 0.1263 - accuracy: 0.9714\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 659us/step - loss: 0.1227 - accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 691us/step - loss: 0.1196 - accuracy: 0.9810\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 693us/step - loss: 0.1187 - accuracy: 0.9810\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 652us/step - loss: 0.1173 - accuracy: 0.9714\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 674us/step - loss: 0.1132 - accuracy: 0.9810\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 681us/step - loss: 0.1111 - accuracy: 0.9714\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 656us/step - loss: 0.1087 - accuracy: 0.9714\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 681us/step - loss: 0.1077 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 678us/step - loss: 0.1076 - accuracy: 0.9905\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 675us/step - loss: 0.1055 - accuracy: 0.9619\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 647us/step - loss: 0.1028 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 632us/step - loss: 0.1042 - accuracy: 0.9714\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 651us/step - loss: 0.1015 - accuracy: 0.9810\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 668us/step - loss: 0.0979 - accuracy: 0.9619\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 656us/step - loss: 0.0950 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 643us/step - loss: 0.0970 - accuracy: 0.9714\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 632us/step - loss: 0.0935 - accuracy: 0.9714\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0909 - accuracy: 0.9714\n",
      "Epoch 81/100\n",
      "  1/105 [..............................] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0d61c0eefab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = []\n",
    "for i in list(range(1,100)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(16, input_dim=4, init='uniform'))\n",
    "    model.add(keras.layers.Activation('sigmoid'))\n",
    "    model.add(keras.layers.Dense(3, init='uniform'))\n",
    "    model.add(keras.layers.Activation('softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train_one_hot, epochs=100, batch_size=i, verbose=1);\n",
    "    loss, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=1)\n",
    "    acc.append(accuracy)\n",
    "    print(\"Accuracy = {:.2f}\".format(accuracy))\n",
    "\n",
    "plt.plot(x=list(range(1,100)), y=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1,100)), acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-12f09ef18763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "inp = keras.layers.Input(shape=(1, 3))\n",
    "double = keras.layers.Lambda(lambda x: 2*x)(inp)\n",
    "model = keras.models.Model(input=inp, output=double)\n",
    "data = np.array([[1,4,8]])\n",
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
